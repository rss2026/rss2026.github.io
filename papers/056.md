---
layout: paper
title: "Demonstrating A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Laura M Smith</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Ilya Kostrikov</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sergey Levine</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p056.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 56
{: style="margin-top: 10px; text-align: center;"}

### [Session 7. Mobile Manipulation and Locomotion]({{ site.baseurl }}/program/papersession?session=7.%20Mobile%20Manipulation%20and%20Locomotion&c1=Hae-Won%20Park&c2=Tirthankar%20Bandyopadhyay&c1a=KAIST&c2a=CSIRO)
{: style="text-align: center;"}

### Demo
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster Session Wednesday, July 12
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 24
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Deep reinforcement learning is a promising approach to learning policies in unstructured environments. Due to its sample inefficiency, though, deep RL applications have primarily focused on simulated environments. In this work, we demonstrate that the recent advancements in machine learning algorithms and libraries combined with careful MDP formulation lead to learning quadruped locomotion in only 20 minutes in the real world. We evaluate our approach on several indoor and outdoor terrains that are known to be challenging for classical, model-based controllers and observe that the robot consistently learns a walking gait on all of these terrains. Finally, we evaluate our design decisions in a simulated environment.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/055/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/057/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
