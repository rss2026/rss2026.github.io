---
layout: paper
title: "Robust and Versatile Bipedal Jumping Control through Reinforcement Learning"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Zhongyu Li</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Xue Bin Peng</div>
    <div class="paper-author-uni">Simon Fraser University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Pieter Abbeel</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sergey Levine</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Glen Berseth</div>
    <div class="paper-author-uni">Université de Montréal, Mila</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Koushil Sreenath</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p052.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 52
{: style="margin-top: 10px; text-align: center;"}

### [Session 7. Mobile Manipulation and Locomotion]({{ site.baseurl }}/program/papersession?session=7.%20Mobile%20Manipulation%20and%20Locomotion&c1=Hae-Won%20Park&c2=Tirthankar%20Bandyopadhyay&c1a=KAIST&c2a=CSIRO)
{: style="text-align: center;"}

#### Poster Session Wednesday, July 12
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 20
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>This work aims to push the limits of agility for bipedal robots by enabling a torque-controlled bipedal robot to perform robust and versatile dynamic jumps in the real world. We present a reinforcement learning framework for training a robot to accomplish a large variety of jumping tasks, such as jumping to different locations and directions. To improve performance on these challenging tasks, we develop a new policy structure that encodes the robot’s long-term input/output (I/O) history while also providing direct access to a short-term I/O history. In order to train a versatile jumping policy, we utilize a multi-stage training scheme that includes different training stages for different objectives. After multi-stage training, the policy can be directly transferred to a real bipedal Cassie robot. Training on different tasks and exploring more diverse scenarios lead to highly robust policies that can exploit the diverse set of learned maneuvers to recover from perturbations or poor landings during real-world deployment. Such robustness in the proposed policy enables Cassie to succeed in completing a variety of challenging jump tasks in the real world, such as standing long jumps, jumping onto elevated platforms, and multi-axes jumps.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/051/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/053/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
