---
layout: paper
title: "Bandit Submodular Maximization for Multi-Robot Coordination in Unpredictable and Partially Observable Environments"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Zirui Xu</div>
    <div class="paper-author-uni">University of Michigan</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Xiaofeng Lin</div>
    <div class="paper-author-uni">University of Michigan</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Vasileios Tzoumas</div>
    <div class="paper-author-uni">University of Michigan</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p109.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 109
{: style="margin-top: 10px; text-align: center;"}

### [Session 14. Multi-Robot and Aerial Systems]({{ site.baseurl }}/program/papersession?session=14.%20Multi-Robot%20and%20Aerial%20Systems&c1=Han-Lim%20Choi&c2=Lantao%20Liu&c1a=KAIST&c2a=Indiana%20University)
{: style="text-align: center;"}

#### Poster Session Friday, July 14
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 13
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>We study the problem of multi-agent coordination in unpredictable and partially observable environments, that is, environments whose future evolution is unknown a priori and that can only be partially observed. We are motivated by the future of autonomy that involves multiple robots coordinating actions in dynamic, unstructured, and partially observable environments to complete complex tasks such as target tracking, environmental mapping, and area monitoring. Such tasks are often modeled as submodular maximization coordination problems due to the information overlap among the robots. We introduce the first submodular coordination algorithm with bandit feedback and bounded tracking regret —bandit feedback is the robots’ ability to compute in hindsight only the effect of their chosen actions, instead of all the alternative actions that they could have chosen instead, due to the partial observability; and tracking regret is the algorithm’s suboptimality with respect to the optimal time-varying actions that fully know the future a priori. The bound gracefully degrades with the environments’ capacity to change adversarially, quantifying how often the robots should re-select actions to learn to coordinate as if they fully knew the future a priori. The algorithm generalizes the seminal Sequential Greedy algorithm by Fisher et al. to the bandit setting, by leveraging submodularity and algorithms for the problem of tracking the best action. We validate our algorithm in simulated scenarios of multi-target tracking.
{: style="color:gray; font-size: 120%; text-align: justified;"}


### Links
- [Supplementary materials](http://www.roboticsproceedings.org/rss19/p109_sup.zip)

<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/108/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/110/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
