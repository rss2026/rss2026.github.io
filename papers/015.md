---
layout: paper
title: "AnyTeleop: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Yuzhe Qin</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Wei Yang</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Binghao Huang</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Karl Van Wyk</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Hao Su</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Xiaolong Wang</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yu-Wei Chao</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Dieter Fox</div>
    <div class="paper-author-uni">NVIDIA Research / University of Washington</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p015.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 15
{: style="margin-top: 10px; text-align: center;"}

### [Session 2. Manipulation from Demonstrations and Teleoperation]({{ site.baseurl }}/program/papersession?session=2.%20Manipulation%20from%20Demonstrations%20and%20Teleoperation&c1=Florian%20Shkurti&c2=Dongheui%20Lee&c1a=University%20of%20Toronto&c2a=TU%20Wien)
{: style="text-align: center;"}

#### Poster Session Tuesday, July 11
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 15
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Vision-based teleoperation offers the possibility to endow robots with human-level intelligence to physically interact with the environment, while only requiring low-cost camera sensors. However, current vision-based teleoperation systems are designed and engineered towards a particular robot model and deploy environment, which scales poorly as the pool of the robot models expanded and the variety of the operating environment increases. In this paper, we propose AnyTeleop, a unified and general teleoperation system to support multiple different arms, hands, realities, and camera configurations within a single system. Although being designed to provide great flexibility to the choice of simulators and real hardware, our system can still achieve great performance. For real-world experiments, AnyTeleop
can outperform a previous system that was designed for the specific robot hardware with a higher success rate, using the same robot. For teleoperation in simulation, AnyTeleop leads to better imitation learning performance, compared with a previous system that is particularly designed for that simulator.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/014/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/016/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
