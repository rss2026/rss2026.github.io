---
layout: paper
title: "To the Noise and Back: Diffusion for Shared Autonomy"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Takuma Yoneda</div>
    <div class="paper-author-uni">Toyota Technological Institute at Chicago</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Luzhe Sun</div>
    <div class="paper-author-uni">University of Chicago</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Ge Yang</div>
    <div class="paper-author-uni">University of Chicago</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Bradly  C Stadie</div>
    <div class="paper-author-uni">Vector Institute</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Matthew R Walter</div>
    <div class="paper-author-uni">Toyota Technological Institute at Chicago</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p014.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 14
{: style="margin-top: 10px; text-align: center;"}

### [Session 2. Manipulation from Demonstrations and Teleoperation]({{ site.baseurl }}/program/papersession?session=2.%20Manipulation%20from%20Demonstrations%20and%20Teleoperation&c1=Florian%20Shkurti&c2=Dongheui%20Lee&c1a=University%20of%20Toronto&c2a=TU%20Wien)
{: style="text-align: center;"}

#### Poster Session Tuesday, July 11
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 14
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Shared autonomy is an operational concept in which a user and an autonomous agent collaboratively control a robotic system. It provides a number of advantages over the extremes of full-teleoperation and full-autonomy in many settings. Traditional approaches to shared autonomy rely on knowledge of the environment dynamics, a discrete space of user goals that is known a priori, or knowledge of the user's policy -- assumptions that are unrealistic in many domains.
Recent works relax some of these assumptions by formulating shared autonomy with model-free deep reinforcement learning (RL).
In particular, they no longer need knowledge of the goal space (e.g., that the goals are discrete or constrained) or environment dynamics. However, they need knowledge of a task-specific reward function to train the policy. Unfortunately, such reward specification can be a difficult and brittle process. On top of that, the formulations inherently rely on human-in-the-loop training, and that necessitates them to prepare a policy that mimics users' behavior.
In this paper, we present a new approach to shared autonomy that employs a modulation of the forward and reverse diffusion process of diffusion models. Our approach does not assume known environment dynamics or the space of user goals, and in contrast to previous work, it does not require any reward feedback, nor does it require access to the user's policy during training. Instead, our framework learns a distribution over a space of desired behaviors. It then employs a diffusion model to translate the user's actions to a sample from this distribution. Crucially, we show that it is possible to carry out this process in a manner that preserves the user's control authority. We evaluate our framework on a series of challenging continuous control tasks, and analyze its ability to effectively correct user actions while maintaining their autonomy.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/013/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/015/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
