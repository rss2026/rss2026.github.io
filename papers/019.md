---
layout: paper
title: "Pre-Training for Robots: Offline RL Enables Learning New Tasks in a Handful of Trials"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Aviral Kumar</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Anikait Singh</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Frederik D Ebert</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Mitsuhiko Nakamoto</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yanlai Yang</div>
    <div class="paper-author-uni">New York University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Chelsea Finn</div>
    <div class="paper-author-uni">Stanford University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sergey Levine</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p019.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 19
{: style="margin-top: 10px; text-align: center;"}

### [Session 3. Self-supervision and RL for Manipulation]({{ site.baseurl }}/program/papersession?session=3.%20Self-supervision%20and%20RL%20for%20Manipulation&c1=Joseph%20Lim&c2=Jens%20Kober&c1a=KAIST&c2a=TU%20Delft)
{: style="text-align: center;"}

#### Poster Session Tuesday, July 11
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 19
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Progress in deep learning highlights the tremendous potential of utilizing diverse datasets for attaining effective generalization and makes it enticing to consider leveraging broad datasets for attaining robust generalization in robotic learning as well. However, in practice we often want to learn a new skill in a new environment that is unlikely to be contained in the prior data. Therefore we ask: how can we leverage existing diverse offline datasets in combination with small amounts of task-specific data to solve new tasks, while still enjoying the generalization benefits of training on large amounts of data? In this paper, we demonstrate that end-to-end offline RL can be an effective approach for doing this, without the need for any representation learning or vision-based pre-training. We present pre-training for robots (PTR), a framework based on offline RL that attempts to effectively learn new tasks by combining pre-training on existing robotic datasets with rapid fine-tuning on a new task, with as a few as 10 demonstrations. PTR utilizes an existing offline RL method, conservative Q-learning (CQL), but extends it to include several crucial design decisions that enable PTR to actually work and outperform a variety of prior methods. To our knowledge, PTR is the first RL method that succeeds at learning new tasks in a new domain on a real WidowX robot with as few as 10 task demonstrations, by effectively leveraging an existing dataset of diverse multi-task robot data collected in a variety of toy kitchens. We also demonstrate that the PTR approach can enable effective autonomous fine-tuning and improvement in a handful of trials, without needing any demonstrations. An accompanying overview video can be found at this anonymous URL: 
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/018/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/020/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
