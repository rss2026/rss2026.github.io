---
layout: paper
title: "Efficient Reinforcement Learning for Autonomous Driving with Parameterized Skills and Priors"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Letian Wang</div>
    <div class="paper-author-uni">University of Toronto</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Jie Liu</div>
    <div class="paper-author-uni">Beihang University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Hao Shao</div>
    <div class="paper-author-uni">Tsinghua University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Wenshuo Wang</div>
    <div class="paper-author-uni">McGill University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Ruobing Chen</div>
    <div class="paper-author-uni">Sensetime Group</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yu Liu</div>
    <div class="paper-author-uni">Sensetime Group</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Steven L Waslander</div>
    <div class="paper-author-uni">University of Toronto</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p102.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 102
{: style="margin-top: 10px; text-align: center;"}

### [Session 13. Autonomous Vehicles & Field Robotics]({{ site.baseurl }}/program/papersession?session=13.%20Autonomous%20Vehicles%20%26%20Field%20Robotics&c1=Shoudong%20Huang&c2=Jen%20Jen%20Chung&c1a=University%20of%20Technology%20Sydney&c2a=Univ.%20of.%20Queensland)
{: style="text-align: center;"}

#### Poster Session Friday, July 14
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 6
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>When autonomous vehicles are deployed on public roads, they will encounter countless and diverse driving situations. Many manually designed driving policies are difficult to scale to the real world. Fortunately, reinforcement learning has shown great success in many tasks by automatic trial and error. However, when it comes to autonomous driving in interactive dense traffic, RL agents either fail to learn reasonable performance or necessitate a large amount of data. Our insight is that when humans learn to drive, they will 1) make decisions over the high-level skill space instead of the low-level control space and 2) leverage expert prior knowledge rather than learning from scratch. Inspired by this, we propose ASAP-RL, an efficient reinforcement learning algorithm for autonomous driving that simultaneously leverages motion skills and expert priors. We first parameterized motion skills, which are diverse enough to cover various complex driving scenarios and situations. A skill parameter inverse recovery method is proposed to convert expert demonstrations from control space to skill space. A simple but effective double initialization technique is proposed to leverage expert priors while bypassing the issue of expert suboptimality and early performance degradation. We validate our proposed method on interactive dense-traffic driving tasks given simple and sparse rewards. Experimental results show that our method can lead to higher learning efficiency and better driving performance relative to previous methods that exploit skills and priors differently. Code is open-sourced to facilitate further research.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/101/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/103/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
