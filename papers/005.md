---
layout: paper
title: "Robot Learning on the Job: Human-in-the-Loop Autonomy and Learning During Deployment"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Huihan Liu</div>
    <div class="paper-author-uni">UT Austin</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Soroush Nasiriany</div>
    <div class="paper-author-uni">UT Austin</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Lance Zhang</div>
    <div class="paper-author-uni">UT Austin</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Zhiyao Bao</div>
    <div class="paper-author-uni">UT Austin</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yuke Zhu</div>
    <div class="paper-author-uni">UT Austin</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p005.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 5
{: style="margin-top: 10px; text-align: center;"}

### Nominated for Best Paper
{: style="margin-top: 10px; font-weight: bold; color: #555555; text-align: center;"}

### [Session 1. Human-Centered Robotics]({{ site.baseurl }}/program/papersession?session=1.%20Human-Centered%20Robotics&c1=Dorsa%20Sadigh&c2=Tapomayukh%20Bhattacharjee&c1a=Stanford%20University&c2a=Cornell%20University)
{: style="text-align: center;"}

#### Poster Session Tuesday, July 11
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 5
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>With the rapid growth of computing powers and recent advances in deep learning, we have witnessed impressive demonstrations of novel robot capabilities in research settings. Nonetheless, these learning systems exhibit brittle generalization and require excessive training data for practical tasks. To harness the capabilities of state-of-the-art robot learning models while embracing their imperfections, we present Sirius, a principled framework for humans and robots to collaborate through a division of work. In this framework, partially autonomous robots are tasked with handling a major portion of decision-making where they work reliably; meanwhile, human operators monitor the process and intervene in challenging situations. Such a human-robot team ensures safe deployments in complex tasks. Further, we introduce a new learning algorithm to improve the policy's performance on the data collected from the task executions. The core idea is re-weighing training samples with approximated human trust and optimizing the policies with weighted behavioral cloning. We evaluate Sirius in simulation and on real hardware, showing that Sirius consistently outperforms baselines over a collection of contact-rich manipulation tasks, achieving an 8% boost in simulation and 27% on real hardware than the state-of-the-art methods in policy success rate, with twice faster convergence and 85% memory size reduction. Videos and more details are available at https://ut-austin-rpl.github.io/sirius/
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/004/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/006/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
