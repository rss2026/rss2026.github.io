---
layout: paper
title: "TerrainNet: Visual Modeling of Complex Terrain for High-speed, Off-road Navigation"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Xiangyun Meng</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Nathan Hatch</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Alexander Lambert</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Anqi Li</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Nolan Wagener</div>
    <div class="paper-author-uni">Georgia Tech</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Matthew Schmittle</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">JoonHo Lee</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Wentao Yuan</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Zoey Chen</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sameul Deng</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Greg Okopal</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Dieter Fox</div>
    <div class="paper-author-uni">NVIDIA Research / University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Byron Boots</div>
    <div class="paper-author-uni">University of Washington</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Amirreza Shaban</div>
    <div class="paper-author-uni">University of Washington</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p103.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 103
{: style="margin-top: 10px; text-align: center;"}

### [Session 13. Autonomous Vehicles & Field Robotics]({{ site.baseurl }}/program/papersession?session=13.%20Autonomous%20Vehicles%20%26%20Field%20Robotics&c1=Shoudong%20Huang&c2=Jen%20Jen%20Chung&c1a=University%20of%20Technology%20Sydney&c2a=Univ.%20of.%20Queensland)
{: style="text-align: center;"}

#### Poster Session Friday, July 14
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 7
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Effective use of camera-based vision systems is essential for robust performance in autonomous off-road driving, particularly in the high-speed regime. Despite success in structured, on-road settings, current end-to-end approaches for scene prediction have yet to be successfully adapted for complex outdoor terrain. To this end, we present TerrainNet, a vision-based terrain perception system for semantic and geometric terrain prediction for aggressive, off-road navigation. The approach relies on several key insights and practical considerations for achieving reliable terrain modeling. The network includes a multi-headed output representation to capture fine- and coarse-grained terrain features necessary for estimating traversability. Accurate depth estimation is achieved using self-supervised depth completion with multi-view RGB and stereo inputs. Requirements for real-time performance and fast inference speeds are met using efficient, learned image feature projections. Furthermore, the model is trained on a large-scale, real-world off-road dataset collected across a variety of diverse outdoor environments. We show how TerrainNet can also be used for costmap prediction and provide a detailed framework for integration into a planning module. We demonstrate the performance of TerrainNet through extensive comparison to current state-of-the-art baselines for camera-only scene prediction. Finally, we showcase the effectiveness of integrating TerrainNet within a complete autonomous-driving stack by conducting a real-world vehicle test in a challenging off-road scenario. 
{: style="color:gray; font-size: 120%; text-align: justified;"}


### Links
- [Supplementary materials](http://www.roboticsproceedings.org/rss19/p103_sup.zip)

<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/102/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/104/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
