---
layout: paper
title: "Bridging Active Exploration and Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Taekyung Kim</div>
    <div class="paper-author-uni">Agency for Defense Development</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Jungwi Mun</div>
    <div class="paper-author-uni">Agency for Defense Development</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Junwon Seo</div>
    <div class="paper-author-uni">Agency for Defense Development</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Beomsu Kim</div>
    <div class="paper-author-uni">Agency for Defense Development</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Seongil Hong</div>
    <div class="paper-author-uni">Agency for Defense Development</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p086.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 86
{: style="margin-top: 10px; text-align: center;"}

### [Session 11. Control & Dynamics]({{ site.baseurl }}/program/papersession?session=11.%20Control%20%26%20Dynamics&c1=Nadia%20Figueroa&c2=Nima%20Fazeli&c1a=University%20of%20Pennsylvania&c2a=University%20of%20Michigan)
{: style="text-align: center;"}

#### Poster Session Thursday, July 13
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 22
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>In recent years, learning-based control in robotics has gained significant attention due to its capability to address complex tasks in real-world environments. With the advances in machine learning algorithms and computational capabilities, this approach is becoming increasingly important for solving challenging control problems in robotics by learning unknown or partially known robot dynamics. Active exploration, in which a robot directs itself to states that yield the highest information gain, is essential for efficient data collection and minimizing human supervision. Similarly, uncertainty-aware deployment has been a growing concern in robotic control, as uncertain actions informed by the learned model can lead to unstable motions or failure. However, active exploration and uncertainty-aware deployment have been studied independently, and there is limited literature that seamlessly integrates them. This paper presents a unified model-based reinforcement learning framework that bridges these two tasks in the robotics control domain. Our framework uses a probabilistic ensemble neural network for dynamics learning, allowing the quantification of epistemic uncertainty via Jensen-RÃ©nyi Divergence. The two opposing tasks of exploration and deployment are optimized through state-of-the-art sampling-based MPC, resulting in efficient collection of training data and successful avoidance of uncertain state-action spaces. We conduct experiments on both autonomous vehicles and wheeled robots, showing promising results for both exploration and deployment.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/085/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/087/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
