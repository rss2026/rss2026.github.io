---
layout: paper
title: "DexPBT: Scaling up Dexterous Manipulation for Hand-Arm Systems with Population Based Training"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Aleksei Petrenko</div>
    <div class="paper-author-uni">University of Southern California</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Arthur Allshire</div>
    <div class="paper-author-uni">University of Toronto</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Gavriel State</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Ankur Handa</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Viktor Makoviychuk</div>
    <div class="paper-author-uni">NVIDIA</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p037.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 37
{: style="margin-top: 10px; text-align: center;"}

### [Session 5. Simulation and Sim2Real]({{ site.baseurl }}/program/papersession?session=5.%20Simulation%20and%20Sim2Real&c1=Gregory%20Chirikjian&c2=Hao%20Su&c1a=National%20University%20of%20Singapore&c2a=UC%20San%20Diego)
{: style="text-align: center;"}

#### Poster Session Wednesday, July 12
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 5
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>In this work, we propose algorithms and methods that enable learning dexterous object manipulation using simulated one- or two-armed robots equipped with multi-fingered hand end-effectors. Using a parallel GPU-accelerated physics simulator (Isaac Gym), we implement challenging tasks for these robots, including regrasping, grasp-and-throw, and object reorientation. To solve these problems we introduce a decentralized Population-Based Training (PBT) algorithm that allows us to massively amplify the exploration capabilities of deep reinforcement learning. We find that this method significantly outperforms regular end-to-end learning and is able to discover robust control policies in challenging tasks. Video demonstrations of learned behaviors and the code can be found at https://sites.google.com/view/dexpbt
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/036/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/038/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
