---
layout: paper
title: "Learning and Adapting Agile Locomotion Skills by Transferring Experience"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Laura M Smith</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">J. Chase Kew</div>
    <div class="paper-author-uni">Google Brain</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Tianyu Li</div>
    <div class="paper-author-uni">Meta</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Linda Luu</div>
    <div class="paper-author-uni">Google Inc</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Xue Bin Peng</div>
    <div class="paper-author-uni">University of California, Berkeley"</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sehoon Ha</div>
    <div class="paper-author-uni">Georgia Tech</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Jie Tan</div>
    <div class="paper-author-uni">Google Inc</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Sergey Levine</div>
    <div class="paper-author-uni">University of California, Berkeley</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p051.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 51
{: style="margin-top: 10px; text-align: center;"}

### [Session 7. Mobile Manipulation and Locomotion]({{ site.baseurl }}/program/papersession?session=7.%20Mobile%20Manipulation%20and%20Locomotion&c1=Hae-Won%20Park&c2=Tirthankar%20Bandyopadhyay&c1a=KAIST&c2a=CSIRO)
{: style="text-align: center;"}

#### Poster Session Wednesday, July 12
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 19
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Legged robots have enormous potential in their range of capabilities, from navigating unstructured terrains to high-speed running. However, these capabilities bring with them difficult control problems, and designing controllers for highly agile dynamic motions remains a substantial challenge for roboticists. Reinforcement learning (RL) offers a promising data-driven approach for automatically training such controllers. However, exploration in these high-dimensional, underactuated systems remains a significant hurdle for enabling legged robots to learn performant, naturalistic, and versatile agility skills. We propose a framework for training complex robotic skills by transferring experience from existing controllers to jumpstart learning new tasks. To leverage controllers we can acquire in practice, we design this framework to be flexible in terms of their source---that is, the controllers may have been optimized for a different objective under different dynamics, or may require different knowledge of the surroundings---and thus may be highly suboptimal for the target task. We show that our method enables learning complex agile jumping behaviors, navigating to goal locations while walking on hind legs, and adapting to new environments. We also demonstrate that the agile behaviors learned in this way are graceful and safe enough to deploy in the real world.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/050/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/052/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
