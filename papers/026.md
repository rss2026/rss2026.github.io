---
layout: paper
title: "Diffusion Policy: Visuomotor Policy Learning via Action Diffusion"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Cheng Chi</div>
    <div class="paper-author-uni">Columbia University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Siyuan Feng</div>
    <div class="paper-author-uni">Toyota Research Institute</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yilun Du</div>
    <div class="paper-author-uni">Massachusetts Institute of Technology</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Zhenjia Xu</div>
    <div class="paper-author-uni">Columbia University</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Eric Cousineau</div>
    <div class="paper-author-uni">Toyota Research Institute</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Benjamin CM Burchfiel</div>
    <div class="paper-author-uni">Toyota Research Institute</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Shuran Song</div>
    <div class="paper-author-uni">Columbia University</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p026.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 26
{: style="margin-top: 10px; text-align: center;"}

### [Session 4. Large Data and Vision-Language Models for Robotics]({{ site.baseurl }}/program/papersession?session=4.%20Large%20Data%20and%20Vision-Language%20Models%20for%20Robotics&c1=Lerrel%20Pinto&c2=Yuke%20Zhu&c1a=NYU&c2a=UT-Austin)
{: style="text-align: center;"}

#### Poster Session Tuesday, July 11
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 26
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot's visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 12 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9%. Diffusion Policy learns the score function of the action distribution and optimizes with respect to this gradient field iteratively during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models. Code, data, and training details will be publicly available.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/025/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/027/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
