---
layout: paper
title: "Fast Monocular Visual-Inertial Initialization Leveraging Learned Single-View Depth"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Nathaniel  W Merrill</div>
    <div class="paper-author-uni">University of Delaware</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Patrick Geneva</div>
    <div class="paper-author-uni">University of Delaware</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Saimouli Katragadda</div>
    <div class="paper-author-uni">University of Delaware</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Chuchu Chen</div>
    <div class="paper-author-uni">University of Delaware</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Guoquan  Huang</div>
    <div class="paper-author-uni">University of Delaware</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p072.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 72
{: style="margin-top: 10px; text-align: center;"}

### Nominated for Best Student Paper
{: style="margin-top: 10px; font-weight: bold; color: #555555; text-align: center;"}

### [Session 9. Robot State Estimation]({{ site.baseurl }}/program/papersession?session=9.%20Robot%20State%20Estimation&c1=Luca%20Carlone&c2=Ayoung%20Kim&c1a=MIT&c2a=Seoul%20National%20University)
{: style="text-align: center;"}

#### Poster Session Thursday, July 13
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 8
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>In monocular visual-inertial navigation systems, it is
ideal to initialize as quickly and robustly as possible. State-of-the-
art initialization methods typically make linear approximations
using the image features and inertial information in order
to initialize in closed-form, and then refine the states with a
nonlinear optimization. While the standard methods typically
wait for a 2sec data window, a recent work has shown that it
is possible to initialize faster (0.5sec) by adding constraints from
a robust but only up-to-scale monocular depth network in the
nonlinear optimization. To further expedite the initialization, in
this work, we leverage the scale-less depth measurements instead
in the linear initialization step that is performed prior to the
nonlinear one, which only requires a single depth image for
the first frame. We show that the typical estimation of each
feature state independently in the closed-form solution can be
replaced by just estimating the scale and offset parameters of
the learned depth map. Interestingly, our formulation makes it
possible to construct small minimal problems in a RANSAC loop,
whereas the typical linear systemâ€™s minimal problem is quite
large and includes every feature state. Experiments show that
our method can improve the overall initialization performance on
popular public datasets (EuRoC MAV and TUM-VI) over state-
of-the-art methods. For the TUM-VI dataset, we show superior
initialization performance with only a 300ms window of data,
which is the smallest ever reported, and show that our method
can initialize more often, robustly, and accurately in different
challenging scenarios.
{: style="color:gray; font-size: 120%; text-align: justified;"}


### Links
- [Supplementary materials](http://www.roboticsproceedings.org/rss19/p072_sup.zip)

<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/071/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/073/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
