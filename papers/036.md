---
layout: paper
title: "Rotating without Seeing: Towards In-hand Dexterity through Touch"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Zhao-Heng Yin</div>
    <div class="paper-author-uni">HKUST</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Binghao Huang</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Yuzhe Qin</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Qifeng Chen</div>
    <div class="paper-author-uni">HKUST</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Xiaolong Wang</div>
    <div class="paper-author-uni">University of California San Diego</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p036.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 36
{: style="margin-top: 10px; text-align: center;"}

### [Session 5. Simulation and Sim2Real]({{ site.baseurl }}/program/papersession?session=5.%20Simulation%20and%20Sim2Real&c1=Gregory%20Chirikjian&c2=Hao%20Su&c1a=National%20University%20of%20Singapore&c2a=UC%20San%20Diego)
{: style="text-align: center;"}

#### Poster Session Wednesday, July 12
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 4
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>Tactile information plays a critical role in human dexterity. It reveals useful contact information that may not be inferred directly from vision. In fact, humans can even perform in-hand dexterous manipulation without using vision. Can we enable the same ability for the multi-finger robot hand? In this paper, we propose to perform in-hand object rotation using only touching without seeing the object. Instead of relying on precise tactile sensing in a small region, we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time. We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects that are not presented in training. Extensive ablations are performed on how tactile information help in-hand manipulation. 
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/035/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/037/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
