---
layout: paper
title: "Self-Supervised Lidar Place Recognition in Overhead Imagery Using Unpaired Data"
invisible: true
---
<div class="paper-authors">
<div class="paper-author-box">
    <div class="paper-author-name">Tim Y. Tang</div>
    <div class="paper-author-uni">University of Oxford</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Daniele De Martini</div>
    <div class="paper-author-uni">University of Oxford</div>
</div>
<div class="paper-author-box">
    <div class="paper-author-name">Paul M Newman</div>
    <div class="paper-author-uni">University of Oxford</div>
</div>

</div><div class="paper-pdf">
<div> <a href="http://www.roboticsproceedings.org/rss19/p098.pdf"><img src="{{ site.baseurl }}/images/paper_link.png" alt="Paper Website" width = "33"  height = "40"/></a> </div>
</div>

### Paper ID 98
{: style="margin-top: 10px; text-align: center;"}

### [Session 13. Autonomous Vehicles & Field Robotics]({{ site.baseurl }}/program/papersession?session=13.%20Autonomous%20Vehicles%20%26%20Field%20Robotics&c1=Shoudong%20Huang&c2=Jen%20Jen%20Chung&c1a=University%20of%20Technology%20Sydney&c2a=Univ.%20of.%20Queensland)
{: style="text-align: center;"}

#### Poster Session Friday, July 14
{: style="margin-top: 10px; color: #555555; text-align: center;"}

#### Poster 2
{: style="margin-top: 10px; color: #555555; text-align: center;"}

<b style="color: black;">Abstract: </b>As much as place recognition is crucial for navigation, mapping and collecting training ground truth, namely sensor data pairs across different locations, are costly and time-consuming.
This paper tackles these by learning lidar place recognition on public overhead imagery and in a self-supervised fashion, with no need for paired lidar and overhead imagery data.
We learn the cross-modal data comparison between lidar and overhead imagery with a multi-step framework.
First, images are transformed into synthetic lidar data and a latent projection is learned.
Next, we discover pseudo pairs of lidar and satellite data from unpaired and asynchronous sequences, and use them for training a final embedding space projection in a cross-modality place recognition framework.
We train and test our approach on real data from various environments and show performances approaching a supervised method using paired data.
{: style="color:gray; font-size: 120%; text-align: justified;"}


<div class="paper-menu">
<a href="{{ site.baseurl }}/program/papers/097/"> <img src="{{ site.baseurl }}/images/previous_paper_icon.png" alt="Previous Paper" title="Previous Paper"/> </a>
<a href="{{ site.baseurl }}/program/papers"><img src="{{ site.baseurl }}/images/overview_icon.png" alt="All Papers" title="All Papers"/> </a>
<a href="{{ site.baseurl }}/program/papers/099/"> <img src="{{ site.baseurl }}/images/next_paper_icon.png" alt="Next Paper" title="Next Paper"/> </a>

</div>
