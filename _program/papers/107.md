---
layout: paper
title: "Demonstrating Multi-Suction Item Picking at Scale via Multi-Modal Learning of Pick Success"
invisible: true
prev_id: "106"
next_id: "108"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Che Wang, Jeroen Vanbaar, Chaitanya Mitash, Shuai Li, Dylan Randle, Weiyao Wang, Sumedh Anand Sontakke, Kostas Bekris, Kapil Katyal</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf">
  <div>
    <a href="https://www.roboticsproceedings.org/rss21/p107.pdf" title="Download PDF" target="_blank">
      <img src="{{ site.baseurl }}/images/paper_link_cardinal_red.png" alt="Paper PDF" width="33" height="40" />
    </a>
  </div>
</div>

### Paper ID 107
{: style="margin-top: 10px; text-align: center;" }

### [Session 11. Manipulation II]({{ site.baseurl }}/program/papersession?session=11.%20Manipulation%20II)
{: style="text-align: center;" }

#### Poster Session (Day 3): Monday, June 23, 6:30-8:00 PM
{: style="margin-top: 10px; color: #555555; text-align: center;" }

<b style="color: black;">Abstract: </b>This work demonstrates how autonomously learning aspects of robotic operation from sparsely-labeled, real-world data of deployed, engineered solutions at industrial scale can provide with solutions that achieve improved performance.  Specifically, it focuses on multi-suction robot picking and performs a comprehensive study on the application of multi-modal visual encoders for predicting the success of candidate robotic picks.  Picking diverse items from unstructured piles is an important and challenging task for robot manipulation in real-world settings, such as warehouses. Methods for picking from clutter must work for an open set of items while simultaneously meeting latency constraints to achieve high throughput. The demonstrated approach utilizes multiple input modalities, such as RGB, depth and semantic segmentation, to estimate the quality of candidate multi-suction picks. The strategy is trained from real-world experience, i.e., given examples of successful and failed attempts to pick items. The training picks have been generated by an engineered strategy. A real-world limitation when learning in such live, industrial setups is that only a single or a few picks can be attempted per scene. The learning strategy first pretrains multi-modal visual models in a self-supervised manner to effectively reconstruct the input modalities in the target domain. A downstream model is then trained to evaluate the quality of multi-suction picks given the learned multi-modal embedding, while the multi-modal model is further fine-tuned. The manuscript provides comprehensive experimental evaluation performed over a large item-picking dataset, an item-picking dataset targeted to include partial occlusions, and a package-picking dataset, which focuses on containers, such as boxes and envelopes, instead of unpackaged items. The evaluation measures performance for different item configurations, pick scenes, and object types. Ablations help to understand the effects of in-domain pretraining, the impact of different modalities and the importance of finetuning. These ablations reveal both the importance of training over multiple modalities but also the ability of models to learn during pretraining the relationship between modalities so that during finetuning and inference, only a subset of them can be used as input.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/106/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fas fa-arrow-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fas fa-list"></i><br>
        <span class="paper-menu-label">Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/108/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fas fa-arrow-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
