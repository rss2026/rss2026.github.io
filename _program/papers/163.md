---
layout: paper
title: "Learning Interpretable Features from Interventions"
invisible: true
prev_id: "162"
next_id: ""
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Erin Hedlund-Botti, Julianna Schalkwyk, Nina Marie Moorman, Chuxuan Yang, Lakshmi Seelam, Sanne Van Waveren, Russell Perkins, Paul Robinette, Matthew Craig Gombolay</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf">
  <div>
    <a href="https://www.roboticsproceedings.org/rss21/p163.pdf" title="Download PDF" target="_blank">
      <img src="{{ site.baseurl }}/images/paper_link_cardinal_red.png" alt="Paper PDF" width="33" height="40" />
    </a>
  </div>
</div>

### Paper ID 163
{: style="margin-top: 10px; text-align: center;" }

### [Session 17. Imitation Learning II]({{ site.baseurl }}/program/papersession?session=17.%20Imitation%20Learning%20II)
{: style="text-align: center;" }

#### Poster Session (Day 4): Tuesday, June 24, 4:00-5:30 PM
{: style="margin-top: 10px; color: #555555; text-align: center;" }

<b style="color: black;">Abstract: </b>The behavior of in-home robots must be adaptable to end-users to adequately address individual users’ needs and preferences. Learning from Demonstration (LfD) is a common approach for customizing robot behavior, enabling non-expert users to teach robots how to perform tasks according to their preferences. While LfD allows users to teach robots tasks, it can be difficult for users to specify their individual needs a priori. Therefore, we propose Learning Interpretable Features from Interventions (LIFI), a user-friendly and streamlined method for personalizing robot behavior through interventions. This approach allows users to easily prompt the robot to adapt its behavior by intervening when the robot’s behavior goes against user expectations. With LIFI, 1) the user intervenes to communicate that the robot is making a mistake, 2) the robot then learns an explanatory feature that describes the failure and 3) uses it to adjust its policy to correct the mistake, aligning with user-specific needs. In a between-subjects evaluation experiment with 48 participants, where the robot attempts household manipulation tasks, we demonstrate that adding features via LIFI improves objective performance and subjective measures, i.e., perceived workload, usability, and trust, compared to a no-feature baseline.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/162/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fas fa-arrow-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fas fa-list"></i><br>
        <span class="paper-menu-label">Papers</span>
      </div>
    </a>
    <div class="paper-menu-icon invisible"></div>
  </div>
</div>
