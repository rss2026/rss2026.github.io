---
layout: paper
title: "Demonstrating REASSEMBLE: A Multimodal Dataset for Contact-rich Robotic Assembly and Disassembly"
invisible: true
prev_id: "58"
next_id: "60"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Daniel Sliwowski, Shail Jadav, Sergej Stanovcic, JÄ™drzej Orbik, Johannes Heidersberger, Dongheui Lee</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf">
  <div>
    <a href="https://www.roboticsproceedings.org/rss21/p059.pdf" title="Download PDF" target="_blank">
      <img src="{{ site.baseurl }}/images/paper_link_cardinal_red.png" alt="Paper PDF" width="33" height="40" />
    </a>
  </div>
</div>

### Paper ID 59
{: style="margin-top: 10px; text-align: center;" }

### [Session 6. Manipulation I]({{ site.baseurl }}/program/papersession?session=6.%20Manipulation%20I)
{: style="text-align: center;" }

#### Poster Session (Day 2): Sunday, June 22, 6:30-8:00 PM
{: style="margin-top: 10px; color: #555555; text-align: center;" }

<b style="color: black;">Abstract: </b>Robotic manipulation remains a core challenge in robotics, particularly for contact-rich tasks such as industrial assembly and disassembly. Existing datasets have significantly advanced learning in manipulation but are primarily focused on simpler tasks like object rearrangement, falling short of capturing the complexity and physical dynamics involved in assembly and disassembly. To bridge this gap, we present REASSEMBLE (Robotic assEmbly disASSEMBLy datasEt), a new dataset designed specifically for contact-rich manipulation tasks. Built around the NIST Assembly Task Board 1 benchmark, REASSEMBLE includes four actions (pick, insert, remove, and place) involving 17 objects. The dataset contains 4,551 demonstrations, of which 4,035 were successful, spanning a total of 781 minutes. Our dataset features multi-modal sensor data, including event cameras, force-torque sensors, microphones, and multi-view RGB cameras. This diverse dataset supports research in areas such as learning contact-rich manipulation, task condition identification, action segmentation, and task inversion learning. The REASSEMBLE will be a valuable resource for advancing robotic manipulation in complex, real-world scenarios. The dataset is publicly available on our project website: https://tuwien-asl.github.io/REASSEMBLE_page/.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/58/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fas fa-arrow-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fas fa-list"></i><br>
        <span class="paper-menu-label">Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/60/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fas fa-arrow-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
